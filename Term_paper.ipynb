{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75646743",
   "metadata": {},
   "source": [
    "# TERM PAPER TEAM DVD TECH-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f034a",
   "metadata": {},
   "source": [
    "## PART 1 - reading in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec6d0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries needed for the tasks.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2838e",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b60a7f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mising file data/SCE-Jan-2013.csv\n",
      "Mising file data/SCE-Feb-2013.csv\n",
      "Mising file data/SCE-Mar-2013.csv\n",
      "Mising file data/SCE-Apr-2013.csv\n",
      "Mising file data/SCE-May-2013.csv\n",
      "Processing file data/SCE-Jun-2013.csv\n",
      "Processing file data/SCE-Jul-2013.csv\n",
      "Processing file data/SCE-Aug-2013.csv\n",
      "Processing file data/SCE-Sep-2013.csv\n",
      "Processing file data/SCE-Oct-2013.csv\n",
      "Processing file data/SCE-Nov-2013.csv\n",
      "Processing file data/SCE-Dec-2013.csv\n",
      "Processing file data/SCE-Jan-2014.csv\n",
      "Processing file data/SCE-Feb-2014.csv\n",
      "Processing file data/SCE-Mar-2014.csv\n",
      "Processing file data/SCE-Apr-2014.csv\n",
      "Processing file data/SCE-May-2014.csv\n",
      "Processing file data/SCE-Jun-2014.csv\n",
      "Processing file data/SCE-Jul-2014.csv\n",
      "Processing file data/SCE-Aug-2014.csv\n",
      "Processing file data/SCE-Sep-2014.csv\n",
      "Processing file data/SCE-Oct-2014.csv\n",
      "Processing file data/SCE-Nov-2014.csv\n",
      "Processing file data/SCE-Dec-2014.csv\n",
      "Processing file data/SCE-Jan-2015.csv\n",
      "Processing file data/SCE-Feb-2015.csv\n",
      "Processing file data/SCE-Mar-2015.csv\n",
      "Processing file data/SCE-Apr-2015.csv\n",
      "Processing file data/SCE-May-2015.csv\n",
      "Processing file data/SCE-Jun-2015.csv\n",
      "Processing file data/SCE-Jul-2015.csv\n",
      "Processing file data/SCE-Aug-2015.csv\n",
      "Processing file data/SCE-Sep-2015.csv\n",
      "Processing file data/SCE-Oct-2015.csv\n",
      "Processing file data/SCE-Nov-2015.csv\n",
      "Processing file data/SCE-Dec-2015.csv\n",
      "Processing file data/SCE-Jan-2016.csv\n",
      "Processing file data/SCE-Feb-2016.csv\n",
      "Processing file data/SCE-Mar-2016.csv\n",
      "Processing file data/SCE-Apr-2016.csv\n",
      "Processing file data/SCE-May-2016.csv\n",
      "Processing file data/SCE-Jun-2016.csv\n",
      "Processing file data/SCE-Jul-2016.csv\n",
      "Processing file data/SCE-Aug-2016.csv\n",
      "Processing file data/SCE-Sep-2016.csv\n",
      "Processing file data/SCE-Oct-2016.csv\n",
      "Processing file data/SCE-Nov-2016.csv\n",
      "Processing file data/SCE-Dec-2016.csv\n",
      "Processing file data/SCE-Jan-2017.csv\n",
      "Processing file data/SCE-Feb-2017.csv\n",
      "Processing file data/SCE-Mar-2017.csv\n",
      "Processing file data/SCE-Apr-2017.csv\n",
      "Processing file data/SCE-May-2017.csv\n",
      "Processing file data/SCE-Jun-2017.csv\n",
      "Processing file data/SCE-Jul-2017.csv\n",
      "Processing file data/SCE-Aug-2017.csv\n",
      "Processing file data/SCE-Sep-2017.csv\n",
      "Processing file data/SCE-Oct-2017.csv\n",
      "Processing file data/SCE-Nov-2017.csv\n",
      "Processing file data/SCE-Dec-2017.csv\n",
      "Processing file data/SCE-Jan-2018.csv\n",
      "Processing file data/SCE-Feb-2018.csv\n",
      "Processing file data/SCE-Mar-2018.csv\n",
      "Processing file data/SCE-Apr-2018.csv\n",
      "Processing file data/SCE-May-2018.csv\n",
      "Processing file data/SCE-Jun-2018.csv\n",
      "Processing file data/SCE-Jul-2018.csv\n",
      "Processing file data/SCE-Aug-2018.csv\n",
      "Processing file data/SCE-Sep-2018.csv\n",
      "Processing file data/SCE-Oct-2018.csv\n",
      "Processing file data/SCE-Nov-2018.csv\n",
      "Processing file data/SCE-Dec-2018.csv\n",
      "Processing file data/SCE-Jan-2019.csv\n",
      "Processing file data/SCE-Feb-2019.csv\n",
      "Processing file data/SCE-Mar-2019.csv\n",
      "Processing file data/SCE-Apr-2019.csv\n",
      "Processing file data/SCE-May-2019.csv\n",
      "Processing file data/SCE-Jun-2019.csv\n",
      "Processing file data/SCE-Jul-2019.csv\n",
      "Processing file data/SCE-Aug-2019.csv\n",
      "Processing file data/SCE-Sep-2019.csv\n",
      "Processing file data/SCE-Oct-2019.csv\n",
      "Processing file data/SCE-Nov-2019.csv\n",
      "Processing file data/SCE-Dec-2019.csv\n",
      "Processing file data/SCE-Jan-2020.csv\n",
      "Processing file data/SCE-Feb-2020.csv\n",
      "Processing file data/SCE-Mar-2020.csv\n",
      "Processing file data/SCE-Apr-2020.csv\n",
      "Processing file data/SCE-May-2020.csv\n",
      "Processing file data/SCE-Jun-2020.csv\n",
      "Processing file data/SCE-Jul-2020.csv\n",
      "Processing file data/SCE-Aug-2020.csv\n",
      "Processing file data/SCE-Sep-2020.csv\n",
      "Processing file data/SCE-Oct-2020.csv\n",
      "Processing file data/SCE-Nov-2020.csv\n",
      "Processing file data/SCE-Dec-2020.csv\n",
      "Processing file data/SCE-Jan-2021.csv\n",
      "Processing file data/SCE-Feb-2021.csv\n",
      "Processing file data/SCE-Mar-2021.csv\n",
      "Processing file data/SCE-Apr-2021.csv\n",
      "Processing file data/SCE-May-2021.csv\n",
      "Processing file data/SCE-Jun-2021.csv\n",
      "Processing file data/SCE-Jul-2021.csv\n",
      "Processing file data/SCE-Aug-2021.csv\n",
      "Processing file data/SCE-Sep-2021.csv\n",
      "Processing file data/SCE-Oct-2021.csv\n",
      "Processing file data/SCE-Nov-2021.csv\n",
      "Processing file data/SCE-Dec-2021.csv\n",
      "Processing file data/SCE-Jan-2022.csv\n",
      "Processing file data/SCE-Feb-2022.csv\n",
      "Processing file data/SCE-Mar-2022.csv\n",
      "Processing file data/SCE-Apr-2022.csv\n",
      "Processing file data/SCE-May-2022.csv\n",
      "Processing file data/SCE-Jun-2022.csv\n",
      "Processing file data/SCE-Jul-2022.csv\n",
      "Processing file data/SCE-Aug-2022.csv\n",
      "Processing file data/SCE-Sep-2022.csv\n",
      "Processing file data/SCE-Oct-2022.csv\n",
      "Processing file data/SCE-Nov-2022.csv\n",
      "Processing file data/SCE-Dec-2022.csv\n",
      "Processing file data/SCE-Jan-2023.csv\n",
      "Processing file data/SCE-Feb-2023.csv\n",
      "Processing file data/SCE-Mar-2023.csv\n",
      "Processing file data/SCE-Apr-2023.csv\n",
      "Processing file data/SCE-May-2023.csv\n",
      "Processing file data/SCE-Jun-2023.csv\n",
      "Processing file data/SCE-Jul-2023.csv\n",
      "Processing file data/SCE-Aug-2023.csv\n",
      "Processing file data/SCE-Sep-2023.csv\n",
      "Processing file data/SCE-Oct-2023.csv\n",
      "Processing file data/SCE-Nov-2023.csv\n",
      "Processing file data/SCE-Dec-2023.csv\n",
      "Processing file data/SCE-Jan-2024.csv\n",
      "Processing file data/SCE-Feb-2024.csv\n",
      "Processing file data/SCE-Mar-2024.csv\n",
      "Processing file data/SCE-Apr-2024.csv\n",
      "Processing file data/SCE-May-2024.csv\n",
      "Processing file data/SCE-Jun-2024.csv\n",
      "Processing file data/SCE-Jul-2024.csv\n",
      "Processing file data/SCE-Aug-2024.csv\n",
      "Processing file data/SCE-Sep-2024.csv\n",
      "Processing file data/SCE-Oct-2024.csv\n",
      "Processing file data/SCE-Nov-2024.csv\n",
      "Processing file data/SCE-Dec-2024.csv\n"
     ]
    }
   ],
   "source": [
    "#reading in the data\n",
    "DATA_PATH = 'data'\n",
    "data = []\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019','2020','2021','2022','2023','2024']\n",
    "for x in years:\n",
    "    for y in months:\n",
    "        try:\n",
    "            filename = f'{DATA_PATH}/SCE-{y}-{x}.csv'\n",
    "            df = pd.read_csv(filename,sep=';')\n",
    "            print(f'Processing file {filename}')\n",
    "            data.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f'Mising file {filename}')\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79e9b8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>wid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>female</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>couple</th>\n",
       "      <th>...</th>\n",
       "      <th>num_lit_q3</th>\n",
       "      <th>num_lit_q3_correct</th>\n",
       "      <th>num_lit_q5</th>\n",
       "      <th>num_lit_q5_correct</th>\n",
       "      <th>num_lit_q6</th>\n",
       "      <th>num_lit_q6_correct</th>\n",
       "      <th>num_lit_q8</th>\n",
       "      <th>num_lit_q8_correct</th>\n",
       "      <th>num_lit_q9</th>\n",
       "      <th>num_lit_q9_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000220</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000224</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70000234</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70000238</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70000239</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176096</th>\n",
       "      <td>75025299</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176097</th>\n",
       "      <td>75025320</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176098</th>\n",
       "      <td>75025337</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176099</th>\n",
       "      <td>75025373</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176100</th>\n",
       "      <td>75025376</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176101 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid     wid        date  weight  female  educ   age  hispanic  \\\n",
       "0       70000220  201306  2013-06-04    16.3     1.0   3.0  28.0       0.0   \n",
       "1       70000224  201306  2013-06-03     0.2     0.0   4.0  65.0       0.0   \n",
       "2       70000234  201306  2013-06-17     4.1     1.0   3.0  41.0       0.0   \n",
       "3       70000238  201306  2013-06-13     3.0     0.0   3.0  74.0       0.0   \n",
       "4       70000239  201306  2013-06-02     1.9     1.0   4.0  67.0       0.0   \n",
       "...          ...     ...         ...     ...     ...   ...   ...       ...   \n",
       "176096  75025299  202412  2024-12-19     0.6     1.0   3.0  33.0       0.0   \n",
       "176097  75025320  202412  2024-12-05     0.8     1.0   4.0  56.0       1.0   \n",
       "176098  75025337  202412  2024-12-21     1.0     1.0   3.0  68.0       0.0   \n",
       "176099  75025373  202412  2024-12-09     2.4     1.0   2.0  58.0       0.0   \n",
       "176100  75025376  202412  2024-12-12     0.5     1.0   4.0  38.0       0.0   \n",
       "\n",
       "        black  couple  ...  num_lit_q3  num_lit_q3_correct  num_lit_q5  \\\n",
       "0         1.0     0.0  ...       100.0                 0.0       100.0   \n",
       "1         0.0     1.0  ...        10.0                 1.0       100.0   \n",
       "2         0.0     1.0  ...        10.0                 1.0       100.0   \n",
       "3         0.0     1.0  ...        10.0                 1.0         1.0   \n",
       "4         0.0     0.0  ...        10.0                 1.0       100.0   \n",
       "...       ...     ...  ...         ...                 ...         ...   \n",
       "176096    0.0     1.0  ...        10.0                 1.0       100.0   \n",
       "176097    0.0     0.0  ...        10.0                 1.0       100.0   \n",
       "176098    0.0     1.0  ...        10.0                 1.0       100.0   \n",
       "176099    0.0     0.0  ...        10.0                 1.0       100.0   \n",
       "176100    0.0     1.0  ...        10.0                 1.0       100.0   \n",
       "\n",
       "        num_lit_q5_correct  num_lit_q6  num_lit_q6_correct  num_lit_q8  \\\n",
       "0                      1.0         5.0                 1.0         NaN   \n",
       "1                      1.0         5.0                 1.0         NaN   \n",
       "2                      1.0         5.0                 1.0         NaN   \n",
       "3                      0.0         5.0                 1.0         NaN   \n",
       "4                      1.0        50.0                 0.0         NaN   \n",
       "...                    ...         ...                 ...         ...   \n",
       "176096                 1.0         5.0                 1.0         2.0   \n",
       "176097                 1.0         5.0                 1.0         3.0   \n",
       "176098                 1.0         5.0                 1.0         3.0   \n",
       "176099                 1.0         1.0                 0.0         3.0   \n",
       "176100                 1.0         2.0                 0.0         3.0   \n",
       "\n",
       "        num_lit_q8_correct  num_lit_q9  num_lit_q9_correct  \n",
       "0                      NaN         NaN                 NaN  \n",
       "1                      NaN         NaN                 NaN  \n",
       "2                      NaN         NaN                 NaN  \n",
       "3                      NaN         NaN                 NaN  \n",
       "4                      NaN         NaN                 NaN  \n",
       "...                    ...         ...                 ...  \n",
       "176096                 0.0         2.0                 1.0  \n",
       "176097                 1.0         2.0                 1.0  \n",
       "176098                 1.0         2.0                 1.0  \n",
       "176099                 1.0         2.0                 1.0  \n",
       "176100                 1.0         2.0                 1.0  \n",
       "\n",
       "[176101 rows x 29 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging all the dataframes in the data list into a single dataframe\n",
    "df = pd.concat(data, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d53737",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3af21a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique individuals in the dataset: 23369\n"
     ]
    }
   ],
   "source": [
    "# 2.1 number of unique individuals in the dataset\n",
    "unique_ind = len(df['userid'].unique())\n",
    "print(f'Number of unique individuals in the dataset: {unique_ind}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f202933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 176101\n"
     ]
    }
   ],
   "source": [
    "#2.2 number of rows in the dataset\n",
    "nrows = len(df)\n",
    "print(f'Number of rows in the dataset: {nrows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f42dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique survey waves: 139\n"
     ]
    }
   ],
   "source": [
    "#2.3 number of unique survey waves\n",
    "unique_wid = len(df['wid'].unique())\n",
    "print(f'Number of unique survey waves: {unique_wid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "388b2e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date observed in the dataset: 1170    2013-06-01\n",
      "Name: date, dtype: object\n",
      "Last date observed in the dataset: 175743    2024-12-31\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2.4 The first and last dates observed in the dataset.\n",
    "first = df['date'].sort_values().head(1)\n",
    "print(f'First date observed in the dataset: {first}')\n",
    "last = df['date'].sort_values().tail(1)\n",
    "print(f'Last date observed in the dataset: {last}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ffa31",
   "metadata": {},
   "source": [
    "## PART 2 - data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fd0ae",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a83161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing numeracy variables(num_lit_X_correct where X is a number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6dc050",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 drop all observationswith missing values\n",
    "#1.for demographic variables(gender,age,education_level)\n",
    "\n",
    "df = df.dropna(subset=['female','age','educ'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6c55ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 175233 entries, 0 to 176100\n",
      "Data columns (total 29 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   userid              175233 non-null  int64  \n",
      " 1   wid                 175233 non-null  int64  \n",
      " 2   date                175233 non-null  object \n",
      " 3   weight              175211 non-null  float64\n",
      " 4   female              175233 non-null  float64\n",
      " 5   educ                175233 non-null  float64\n",
      " 6   age                 175233 non-null  float64\n",
      " 7   hispanic            175146 non-null  float64\n",
      " 8   black               175233 non-null  float64\n",
      " 9   couple              162489 non-null  float64\n",
      " 10  num_kids            175205 non-null  float64\n",
      " 11  owner               23204 non-null   float64\n",
      " 12  inflation           174572 non-null  float64\n",
      " 13  house_price_change  174939 non-null  float64\n",
      " 14  prob_stocks_up      174282 non-null  float64\n",
      " 15  num_lit_q1          23153 non-null   float64\n",
      " 16  num_lit_q1_correct  23153 non-null   float64\n",
      " 17  num_lit_q2          23124 non-null   float64\n",
      " 18  num_lit_q2_correct  23124 non-null   float64\n",
      " 19  num_lit_q3          23072 non-null   float64\n",
      " 20  num_lit_q3_correct  23072 non-null   float64\n",
      " 21  num_lit_q5          23095 non-null   float64\n",
      " 22  num_lit_q5_correct  23095 non-null   float64\n",
      " 23  num_lit_q6          23010 non-null   float64\n",
      " 24  num_lit_q6_correct  23010 non-null   float64\n",
      " 25  num_lit_q8          17902 non-null   float64\n",
      " 26  num_lit_q8_correct  17902 non-null   float64\n",
      " 27  num_lit_q9          17851 non-null   float64\n",
      " 28  num_lit_q9_correct  17851 non-null   float64\n",
      "dtypes: float64(26), int64(2), object(1)\n",
      "memory usage: 40.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10f67e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>wid</th>\n",
       "      <th>date</th>\n",
       "      <th>weight</th>\n",
       "      <th>female</th>\n",
       "      <th>educ</th>\n",
       "      <th>age</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>black</th>\n",
       "      <th>couple</th>\n",
       "      <th>...</th>\n",
       "      <th>num_lit_q3_correct</th>\n",
       "      <th>num_lit_q5</th>\n",
       "      <th>num_lit_q5_correct</th>\n",
       "      <th>num_lit_q6</th>\n",
       "      <th>num_lit_q6_correct</th>\n",
       "      <th>num_lit_q8</th>\n",
       "      <th>num_lit_q8_correct</th>\n",
       "      <th>num_lit_q9</th>\n",
       "      <th>num_lit_q9_correct</th>\n",
       "      <th>college</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000220</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000224</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70000234</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-17</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70000238</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70000239</td>\n",
       "      <td>201306</td>\n",
       "      <td>2013-06-02</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176096</th>\n",
       "      <td>75025299</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-19</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176097</th>\n",
       "      <td>75025320</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-05</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176098</th>\n",
       "      <td>75025337</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176099</th>\n",
       "      <td>75025373</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-09</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176100</th>\n",
       "      <td>75025376</td>\n",
       "      <td>202412</td>\n",
       "      <td>2024-12-12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173166 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid     wid        date  weight  female  educ   age  hispanic  \\\n",
       "0       70000220  201306  2013-06-04    16.3     1.0   3.0  28.0       0.0   \n",
       "1       70000224  201306  2013-06-03     0.2     0.0   4.0  65.0       0.0   \n",
       "2       70000234  201306  2013-06-17     4.1     1.0   3.0  41.0       0.0   \n",
       "3       70000238  201306  2013-06-13     3.0     0.0   3.0  74.0       0.0   \n",
       "4       70000239  201306  2013-06-02     1.9     1.0   4.0  67.0       0.0   \n",
       "...          ...     ...         ...     ...     ...   ...   ...       ...   \n",
       "176096  75025299  202412  2024-12-19     0.6     1.0   3.0  33.0       0.0   \n",
       "176097  75025320  202412  2024-12-05     0.8     1.0   4.0  56.0       1.0   \n",
       "176098  75025337  202412  2024-12-21     1.0     1.0   3.0  68.0       0.0   \n",
       "176099  75025373  202412  2024-12-09     2.4     1.0   2.0  58.0       0.0   \n",
       "176100  75025376  202412  2024-12-12     0.5     1.0   4.0  38.0       0.0   \n",
       "\n",
       "        black  couple  ...  num_lit_q3_correct  num_lit_q5  \\\n",
       "0         1.0     0.0  ...                 0.0       100.0   \n",
       "1         0.0     1.0  ...                 1.0       100.0   \n",
       "2         0.0     1.0  ...                 1.0       100.0   \n",
       "3         0.0     1.0  ...                 1.0         1.0   \n",
       "4         0.0     0.0  ...                 1.0       100.0   \n",
       "...       ...     ...  ...                 ...         ...   \n",
       "176096    0.0     1.0  ...                 1.0       100.0   \n",
       "176097    0.0     0.0  ...                 1.0       100.0   \n",
       "176098    0.0     1.0  ...                 1.0       100.0   \n",
       "176099    0.0     0.0  ...                 1.0       100.0   \n",
       "176100    0.0     1.0  ...                 1.0       100.0   \n",
       "\n",
       "        num_lit_q5_correct  num_lit_q6  num_lit_q6_correct  num_lit_q8  \\\n",
       "0                      1.0         5.0                 1.0         NaN   \n",
       "1                      1.0         5.0                 1.0         NaN   \n",
       "2                      1.0         5.0                 1.0         NaN   \n",
       "3                      0.0         5.0                 1.0         NaN   \n",
       "4                      1.0        50.0                 0.0         NaN   \n",
       "...                    ...         ...                 ...         ...   \n",
       "176096                 1.0         5.0                 1.0         2.0   \n",
       "176097                 1.0         5.0                 1.0         3.0   \n",
       "176098                 1.0         5.0                 1.0         3.0   \n",
       "176099                 1.0         1.0                 0.0         3.0   \n",
       "176100                 1.0         2.0                 0.0         3.0   \n",
       "\n",
       "        num_lit_q8_correct  num_lit_q9  num_lit_q9_correct  college  \n",
       "0                      NaN         NaN                 NaN        0  \n",
       "1                      NaN         NaN                 NaN        1  \n",
       "2                      NaN         NaN                 NaN        0  \n",
       "3                      NaN         NaN                 NaN        0  \n",
       "4                      NaN         NaN                 NaN        1  \n",
       "...                    ...         ...                 ...      ...  \n",
       "176096                 0.0         2.0                 1.0        0  \n",
       "176097                 1.0         2.0                 1.0        1  \n",
       "176098                 1.0         2.0                 1.0        0  \n",
       "176099                 1.0         2.0                 1.0        0  \n",
       "176100                 1.0         2.0                 1.0        1  \n",
       "\n",
       "[173166 rows x 30 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.2  The three expectations questions about inflation, house price changes, and the stock market\n",
    "#using the dropna function to drop rows with missing values in the specified columns\n",
    "df = df.dropna(subset=['inflation','house_price_change','prob_stocks_up'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.3 The seven numeracy questions (after you have forward-filled nonmissing values in step 1!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4146f6e",
   "metadata": {},
   "source": [
    "### TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflation: dropped 190 outliers\n",
      "house_price_change: dropped 194 outliers\n",
      "prob_stocks_up: dropped 0 outliers\n"
     ]
    }
   ],
   "source": [
    "#3 Drop outliers (implausibly small or large values). For each expectations response:\n",
    "expect_vars = [\"inflation\", \"house_price_change\", \"prob_stocks_up\"]\n",
    "#creating a for loop to drop outliers for each variable in expect_vars\n",
    "for var in expect_vars:\n",
    "    low, high = df[var].quantile([0.001, 0.999])\n",
    "    before = len(df)\n",
    "    df = df[(df[var] >= low) & (df[var] <= high)]\n",
    "    print(f\"{var}: dropped {before - len(df)} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb40152e",
   "metadata": {},
   "source": [
    "### TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32e9722e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "176096    0\n",
       "176097    1\n",
       "176098    0\n",
       "176099    0\n",
       "176100    1\n",
       "Name: college, Length: 173166, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column college equal to 1 if an individual has at least a bachelor’s degree, and 0\n",
    "#otherwise.\n",
    "df['college']=  (df[\"educ\"] >= 4).astype(int)\n",
    "df['college']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68046b43",
   "metadata": {},
   "source": [
    "### TASK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "708d6750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of numeracy scores (% of individuals):\n",
      "num_correct\n",
      "num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct    100.0\n",
      "Name: userid, dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert ['num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n ...\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDistribution of numeracy scores (\u001b[39m\u001b[38;5;132;01m% o\u001b[39;00m\u001b[33mf individuals):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m((dist * \u001b[32m100\u001b[39m).round(\u001b[32m1\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m median_score = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_correct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mnum_lit_high\u001b[39m\u001b[33m\"\u001b[39m] = (df[\u001b[33m\"\u001b[39m\u001b[33mnum_correct\u001b[39m\u001b[33m\"\u001b[39m] > median_score).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\series.py:6570\u001b[39m, in \u001b[36mSeries.median\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6562\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6563\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmedian\u001b[39m(\n\u001b[32m   6564\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6568\u001b[39m     **kwargs,\n\u001b[32m   6569\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6570\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\generic.py:12450\u001b[39m, in \u001b[36mNDFrame.median\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12443\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmedian\u001b[39m(\n\u001b[32m  12444\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12445\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12448\u001b[39m     **kwargs,\n\u001b[32m  12449\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12450\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12451\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedian\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmedian\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12452\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\generic.py:12396\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12392\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12394\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12398\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\series.py:6468\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6463\u001b[39m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[32m   6464\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6465\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6466\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6467\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6468\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vanya Nagar\\anaconda3\\envs\\TECH2\\Lib\\site-packages\\pandas\\core\\nanops.py:787\u001b[39m, in \u001b[36mnanmedian\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    785\u001b[39m     inferred = lib.infer_dtype(values)\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    789\u001b[39m     values = values.astype(\u001b[33m\"\u001b[39m\u001b[33mf8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Cannot convert ['num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n ...\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'\n 'num_lit_1_correctnum_lit_2_correctnum_lit_3_correctnum_lit_5_correctnum_lit_6_correctnum_lit_8_correctnum_lit_9_correct'] to numeric"
     ]
    }
   ],
   "source": [
    "#total number of correct answers across the seven numeracy questions\n",
    "df[\"num_correct\"] = df[num_cols].sum(axis=1)\n",
    "dist = df.groupby(\"num_correct\")[\"userid\"].nunique() / df[\"userid\"].nunique()\n",
    "print(\"\\nDistribution of numeracy scores (% of individuals):\")\n",
    "print((dist * 100).round(1))\n",
    "\n",
    "median_score = df[\"num_correct\"].median()\n",
    "df[\"num_lit_high\"] = (df[\"num_correct\"] > median_score).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cb2b9",
   "metadata": {},
   "source": [
    "### TASK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea505d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the same sample statistics as in Part 1 for the final data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8487e7a",
   "metadata": {},
   "source": [
    "## PART 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedeac2",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8147e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TECH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
