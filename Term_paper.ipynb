{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75646743",
   "metadata": {},
   "source": [
    "# TERM PAPER TEAM DVD TECH-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629f034a",
   "metadata": {},
   "source": [
    "## PART 1 - reading in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec6d0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the libraries needed for the tasks.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2838e",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60a7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the data\n",
    "DATA_PATH = 'data'\n",
    "data = []\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "years = ['2013','2014','2015','2016','2017','2018','2019','2020','2021','2022','2023','2024']\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        try:\n",
    "            filename = f'{DATA_PATH}/SCE-{month}-{year}.csv'\n",
    "            df = pd.read_csv(filename,sep=';')\n",
    "            data.append(df)\n",
    "        except FileNotFoundError:\n",
    "            # Error handelig since data is not present for all months in 2013\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e9b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging all the dataframes in the data list into a single dataframe\n",
    "df = pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d53737",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3af21a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique individuals in the dataset: 23369\n"
     ]
    }
   ],
   "source": [
    "# 2.1 number of unique individuals in the dataset\n",
    "def num_unique_id():\n",
    "    return len(df['userid'].unique())\n",
    "\n",
    "print(f'Number of unique individuals in the dataset: {num_unique_id()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f202933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 176101\n"
     ]
    }
   ],
   "source": [
    "#2.2 number of rows in the dataset\n",
    "def num_rows():\n",
    "    return len(df)\n",
    "\n",
    "print(f'Number of rows in the dataset: {num_rows()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f42dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique survey waves: 139\n"
     ]
    }
   ],
   "source": [
    "#2.3 number of unique survey waves\n",
    "def unique_wid():\n",
    "    return len(df['wid'].unique())\n",
    "\n",
    "print(f'Number of unique survey waves: {unique_wid()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388b2e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date observed in the dataset: 2013-06-01\n",
      "Last date observed in the dataset: 2024-12-31\n"
     ]
    }
   ],
   "source": [
    "#2.4 The first and last dates observed in the dataset.\n",
    "first = df['date'].min()\n",
    "print(f'First date observed in the dataset: {first}')\n",
    "last = df['date'].max()\n",
    "print(f'Last date observed in the dataset: {last}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ffa31",
   "metadata": {},
   "source": [
    "## PART 2 - data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fd0ae",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9a83161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numeracy variables(num_lit_X_correct where X is a number)\n",
    "num_cols = ['num_lit_q1_correct', 'num_lit_q2_correct', 'num_lit_q3_correct', 'num_lit_q5_correct', 'num_lit_q6_correct', 'num_lit_q8_correct', 'num_lit_q9_correct']\n",
    "\n",
    "# Fill missing numeracy values with the first available non-missing value per user\n",
    "# bfill() is used in case the first value is NaN, ensuring that a non-missing value is used to fill in columns backwards as well\n",
    "for col in num_cols:\n",
    "    df[col] = df.groupby('userid')[col].transform(lambda x: x.ffill().bfill())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6dc050",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5732b953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped demographics:  868\n"
     ]
    }
   ],
   "source": [
    "#2 drop all observationswith missing values\n",
    "#1.for demographic variables(gender,age,education_level)\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['female','age','educ'])\n",
    "after_demographics = len(df)\n",
    "print(\"Dropped demographics: \", before - after_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f67e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped expectations:  1683\n"
     ]
    }
   ],
   "source": [
    "#2.2  The three expectations questions about inflation, house price changes, and the stock market\n",
    "#using the dropna function to drop rows with missing values in the specified columns\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['inflation','house_price_change','prob_stocks_up'])\n",
    "after_expectations = len(df)\n",
    "print(\"Dropped expectations: \", before - after_expectations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de08d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped demographics:  35974\n"
     ]
    }
   ],
   "source": [
    "#2.3 The seven numeracy questions (after you have forward-filled nonmissing values in step 1!)\n",
    "df = df.dropna(subset=num_cols)\n",
    "after_numeracy = len(df)\n",
    "print(\"Dropped demographics: \", after_expectations - after_numeracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4146f6e",
   "metadata": {},
   "source": [
    "### TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d995d84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inflation: dropped 119 outliers\n",
      "house_price_change: dropped 179 outliers\n",
      "prob_stocks_up: dropped 0 outliers\n"
     ]
    }
   ],
   "source": [
    "#3 Drop outliers (implausibly small or large values). For each expectations response:\n",
    "expect_vars = [\"inflation\", \"house_price_change\", \"prob_stocks_up\"]\n",
    "#creating a for loop to drop outliers for each variable in expect_vars\n",
    "for var in expect_vars:\n",
    "    low, high = df[var].quantile([0.001, 0.999])\n",
    "    before = len(df)\n",
    "    df = df[(df[var] >= low) & (df[var] <= high)]\n",
    "    print(f\"{var}: dropped {before - len(df)} outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb40152e",
   "metadata": {},
   "source": [
    "### TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32e9722e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30936     1\n",
       "30937     1\n",
       "30942     1\n",
       "30943     1\n",
       "30944     1\n",
       "         ..\n",
       "176096    0\n",
       "176097    1\n",
       "176098    0\n",
       "176099    0\n",
       "176100    1\n",
       "Name: college, Length: 137278, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new column college equal to 1 if an individual has at least a bachelorâ€™s degree, and 0\n",
    "#otherwise.\n",
    "df['college']=  (df[\"educ\"] >= 4).astype(int)\n",
    "df['college']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68046b43",
   "metadata": {},
   "source": [
    "### TASK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "708d6750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of numeracy scores (% of individuals):\n",
      "num_correct\n",
      "0.0     0.1\n",
      "1.0     0.7\n",
      "2.0     2.4\n",
      "3.0     5.7\n",
      "4.0    10.5\n",
      "5.0    16.9\n",
      "6.0    27.4\n",
      "7.0    36.2\n",
      "Name: userid, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#total number of correct answers across the seven numeracy questions\n",
    "df[\"num_correct\"] = df[num_cols].sum(axis=1)\n",
    "dist = df.groupby(\"num_correct\")[\"userid\"].nunique() / df[\"userid\"].nunique()\n",
    "print(\"\\nDistribution of numeracy scores (% of individuals):\")\n",
    "print((dist * 100).round(1))\n",
    "\n",
    "median_score = df[\"num_correct\"].median()\n",
    "df[\"num_lit_high\"] = (df[\"num_correct\"] > median_score).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cb2b9",
   "metadata": {},
   "source": [
    "### TASK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea505d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique individuals in the dataset: 17701\n",
      "Number of rows in the dataset: 137278\n",
      "Number of unique survey waves: 117\n"
     ]
    }
   ],
   "source": [
    "# Report the same sample statistics as in Part 1 for the final data set.\n",
    "print(f'Number of unique individuals in the dataset: {num_unique_id()}')\n",
    "print(f'Number of rows in the dataset: {num_rows()}')\n",
    "print(f'Number of unique survey waves: {unique_wid()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8487e7a",
   "metadata": {},
   "source": [
    "## PART 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedeac2",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8147e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
